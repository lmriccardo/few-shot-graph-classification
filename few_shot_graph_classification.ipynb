{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "few-shot-graph-classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Few-Shot Graph Classification"
      ],
      "metadata": {
        "id": "6YcW8xJl1woa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "TORCH = torch.__version__.split('+')[0]\n",
        "CUDA = 'cu' + torch.version.cuda.replace('.','')\n",
        "\n",
        "!pip install pytorch-lightning\n",
        "!pip install pyyaml==5.4.1\n",
        "!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "id": "SJDbVhtHfKXl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dac16a5-cea5-4880-f3a6-150d25185c2a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-1.7.1-py3-none-any.whl (701 kB)\n",
            "\u001b[K     |████████████████████████████████| 701 kB 8.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.1.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.21.6)\n",
            "Collecting PyYAML>=5.4\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 49.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.9.* in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.12.0+cu113)\n",
            "Collecting torchmetrics>=0.7.0\n",
            "  Downloading torchmetrics-0.9.3-py3-none-any.whl (419 kB)\n",
            "\u001b[K     |████████████████████████████████| 419 kB 75.7 MB/s \n",
            "\u001b[?25hCollecting pyDeprecate>=0.3.1\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Collecting tensorboard>=2.9.1\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 51.1 MB/s \n",
            "\u001b[?25hCollecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
            "  Downloading fsspec-2022.7.1-py3-none-any.whl (141 kB)\n",
            "\u001b[K     |████████████████████████████████| 141 kB 40.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.64.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning) (3.0.9)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.47.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (57.4.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (0.37.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.35.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (0.6.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.8.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (0.2.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (1.15.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.9.1->pytorch-lightning) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.9.1->pytorch-lightning) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning) (3.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (6.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (22.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.8.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (0.13.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.3.0)\n",
            "Installing collected packages: fsspec, torchmetrics, tensorboard, PyYAML, pyDeprecate, pytorch-lightning\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires tensorboard<2.9,>=2.8, but you have tensorboard 2.9.1 which is incompatible.\u001b[0m\n",
            "Successfully installed PyYAML-6.0 fsspec-2022.7.1 pyDeprecate-0.3.2 pytorch-lightning-1.7.1 tensorboard-2.9.1 torchmetrics-0.9.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyyaml==5.4.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 7.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyyaml\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "Successfully installed pyyaml-5.4.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.12.0+cu113.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 8.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.12.0+cu113.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_sparse-0.6.14-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 8.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.14\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.12.0+cu113.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl (2.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 6.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.12.0+cu113.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-1.12.0%2Bcu113/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (709 kB)\n",
            "\u001b[K     |████████████████████████████████| 709 kB 6.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.0.4.tar.gz (407 kB)\n",
            "\u001b[K     |████████████████████████████████| 407 kB 7.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.7.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2022.6.15)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.4-py3-none-any.whl size=616603 sha256=06752e4da9c6101d77d61fc2e19b7064eb18fc589ff68c72924b4a8b955653d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/a6/a4/ca18c3051fcead866fe7b85700ee2240d883562a1bc70ce421\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import Dict, List, Tuple, Union, \\\n",
        "                   Sequence, TypeVar, Generic, \\\n",
        "                   Optional\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import plotly\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch_geometric as gtorch\n",
        "import torch_geometric.nn as gnn\n",
        "import torch_geometric.data as gdata\n",
        "import torch_geometric.loader as gloader\n",
        "import torch_geometric.utils as gutils\n",
        "\n",
        "import random\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "ir1hptyLJMoN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a66ea385-77ac-4832-d6a2-b04d605ff48c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
            "  defaults = yaml.load(f)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load dataset\n",
        "\n",
        "The dataset I will load is the TRIANGLE used in the AS-MAML paper (here's the [link](https://arxiv.org/pdf/2003.08246.pdf))"
      ],
      "metadata": {
        "id": "dyTZTbi_JGlK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT_PATH = os.getcwd()\n",
        "GRAPH_ATTRIBUTE  = os.path.join(ROOT_PATH, \"TRIANGLES/TRIANGLES_graph_attributes.txt\")\n",
        "GRAPH_LABELS     = os.path.join(ROOT_PATH, \"TRIANGLES/TRIANGLES_graph_labels.txt\")\n",
        "NODE_NATTRIBUTE  = os.path.join(ROOT_PATH, \"TRIANGLES/TRIANGLES_node_attributes.txt\")\n",
        "GRAPH_INDICATOR  = os.path.join(ROOT_PATH, \"TRIANGLES/TRIANGLES_graph_indicator.txt\")\n",
        "GRAPH_A          = os.path.join(ROOT_PATH, \"TRIANGLES/TRIANGLES_A.txt\")\n",
        "\n",
        "T = TypeVar('T')\n",
        "\n",
        "LOAD_DATASET = True\n",
        "\n",
        "if LOAD_DATASET:\n",
        "    !wget https://cloud-storage.eu-central-1.linodeobjects.com/TRIANGLES.zip\n",
        "    !unzip TRIANGLES.zip"
      ],
      "metadata": {
        "id": "TZW6CTnLJJNF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abce5842-ead2-46e8-d1ea-2bf369f1562a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-10 13:57:32--  https://cloud-storage.eu-central-1.linodeobjects.com/TRIANGLES.zip\n",
            "Resolving cloud-storage.eu-central-1.linodeobjects.com (cloud-storage.eu-central-1.linodeobjects.com)... 172.105.80.252, 139.162.182.14, 172.105.69.135, ...\n",
            "Connecting to cloud-storage.eu-central-1.linodeobjects.com (cloud-storage.eu-central-1.linodeobjects.com)|172.105.80.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6339762 (6.0M) [application/x-zip-compressed]\n",
            "Saving to: ‘TRIANGLES.zip’\n",
            "\n",
            "TRIANGLES.zip       100%[===================>]   6.05M  4.56MB/s    in 1.3s    \n",
            "\n",
            "2022-08-10 13:57:35 (4.56 MB/s) - ‘TRIANGLES.zip’ saved [6339762/6339762]\n",
            "\n",
            "Archive:  TRIANGLES.zip\n",
            "   creating: TRIANGLES/\n",
            "  inflating: TRIANGLES/README.txt    \n",
            "  inflating: TRIANGLES/TRIANGLES_A.txt  \n",
            "  inflating: TRIANGLES/TRIANGLES_graph_attributes.txt  \n",
            "  inflating: TRIANGLES/TRIANGLES_graph_indicator.txt  \n",
            "  inflating: TRIANGLES/TRIANGLES_graph_labels.txt  \n",
            "  inflating: TRIANGLES/TRIANGLES_node_attributes.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph_attribute      = open(GRAPH_ATTRIBUTE).readlines()\n",
        "graph_labels         = open(GRAPH_LABELS).readlines()\n",
        "graph_node_attribute = open(NODE_NATTRIBUTE).readlines()\n",
        "graph_indicator      = open(GRAPH_INDICATOR).readlines()\n",
        "graph_a              = open(GRAPH_A).readlines()"
      ],
      "metadata": {
        "id": "37zpzkLaLKHw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GeneratorTxt2Graph:\n",
        "    def __init__(self, **kargs) -> None:\n",
        "        self.__graph_attribute  = kargs['graph_attribute']\n",
        "        self.__graph_labels     = kargs['graph_labels']\n",
        "        self.__node_attribute   = kargs['node_attribute']\n",
        "        self.__graph_indicator  = kargs['graph_indicator']\n",
        "        self.__graph_adjacency  = kargs['graph_adjacency']\n",
        "        self.__node_labels      = kargs['node_labels']\n",
        "        self.__edge_labels      = kargs['edge_labels']\n",
        "        self.__edge_attributes  = kargs['edge_attributes']\n",
        "\n",
        "    def _collect_nodes(self) -> Tuple[Dict[str, List[int]], Dict[str, Tuple[str, int]]]:\n",
        "        \"\"\" Look at the graph_indicator.txt file and return\n",
        "        a dictionary containing as keys the ID of the graph\n",
        "        and as values a list of nodes belonging to that graph \"\"\"\n",
        "        print(\"--- Collecting Nodes ... \")\n",
        "\n",
        "        nodes, i_nodes = dict(), dict()\n",
        "        for i, graph_id in enumerate(self.__graph_indicator):\n",
        "            graph_id = graph_id[:-1]\n",
        "            if graph_id not in nodes:\n",
        "                nodes[graph_id] = []\n",
        "        \n",
        "            nodes[graph_id].append(i + 1)\n",
        "            i_nodes[i + 1] = [graph_id, i + 1]\n",
        "        \n",
        "        return nodes, i_nodes\n",
        "\n",
        "    def _collect_edges(self, i_nodes: Dict[str, Tuple[str, int]], \n",
        "                             direct: bool=False) -> Dict[str, List[Tuple[int, int]]]:\n",
        "        \"\"\" Look at the graph_A.txt file and return a dictionary\n",
        "        containing as keys the ID of the graph and as values\n",
        "        a list of edges of that graph \"\"\"\n",
        "        print(\"--- Collecting Edges ...\")\n",
        "\n",
        "        edges = dict()\n",
        "        for line in self.__graph_adjacency:\n",
        "            if line == \"\\n\":\n",
        "                continue\n",
        "            \n",
        "            a, b = line.split(\", \")\n",
        "            a, b = a.strip(), b.strip()\n",
        "\n",
        "            graph_a, node_a = i_nodes[int(a)]\n",
        "            graph_b, node_b = i_nodes[int(b)]\n",
        "\n",
        "            assert graph_a == graph_b, f\"Two graphs are not equal: {graph_a} != {graph_b}\"\n",
        "\n",
        "            if graph_a not in edges:\n",
        "                edges[graph_a] = []\n",
        "            \n",
        "            edges[graph_a].append((node_a, node_b))\n",
        "\n",
        "        return edges\n",
        "    \n",
        "    def _collect_node_attributes(self, i_nodes: Dict[str, Tuple[str, int]]) -> None:\n",
        "        \"\"\" Set attributes for each nodes \"\"\"\n",
        "        print(\"--- Collecting Node Attributes ...\")\n",
        "        for i, attr in enumerate(self.__node_attribute):\n",
        "            node_i = i_nodes[i + 1]\n",
        "            attrs = attr.split(\", \")\n",
        "            attrs[-1] = attrs[-1][:-1]\n",
        "            node_i.append({f\"attr{i}\" : attr for i, attr in enumerate(attrs)})\n",
        "\n",
        "    def _collect_graph_labels(self, graphs: Dict[str, nx.Graph]) -> None:\n",
        "        \"\"\" Set the attribute label for each graph \"\"\"\n",
        "        print(\"--- Collecting Graph Labels ...\")\n",
        "        for i, label in enumerate(self.__graph_labels):\n",
        "            graph_i = graphs[str(i + 1)]\n",
        "            graphs[str(i + 1)] = (graph_i, label[:-1])\n",
        "\n",
        "    # TODO: _collect_node_labels, _collect_edge_labels, _collect_edge_attributes\n",
        "\n",
        "    def generate(self) -> Dict[str, nx.Graph]:\n",
        "        \"\"\" Return a dictionary of {i : Graph_i} \"\"\"\n",
        "        # Get Nodes and Edges\n",
        "        nodes, i_nodes = self._collect_nodes()\n",
        "        edges          = self._collect_edges(i_nodes, False)\n",
        "\n",
        "        # Set attributes for nodes\n",
        "        self._collect_node_attributes(i_nodes)\n",
        "        \n",
        "        # Create the graphs\n",
        "        graphs = dict()\n",
        "        for graph_id in edges:\n",
        "            g = nx.Graph()\n",
        "            g_nodes = [(i_nodes[n][1], i_nodes[n][-1]) for n in nodes[graph_id]]\n",
        "            g_edges = edges[graph_id]\n",
        "\n",
        "            g.add_nodes_from(g_nodes)\n",
        "            g.add_edges_from(g_edges)\n",
        "\n",
        "            graphs[graph_id] = g\n",
        "\n",
        "        # Set labels for graph\n",
        "        self._collect_graph_labels(graphs)\n",
        "\n",
        "        return graphs"
      ],
      "metadata": {
        "id": "Dv3ENeuqVVOZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graphs_gen = GeneratorTxt2Graph(graph_attribute=graph_attribute,\n",
        "                                graph_labels=graph_labels,\n",
        "                                node_attribute=graph_node_attribute,\n",
        "                                graph_indicator=graph_indicator,\n",
        "                                graph_adjacency=graph_a,\n",
        "                                node_labels=None,\n",
        "                                edge_labels=None,\n",
        "                                edge_attributes=None)"
      ],
      "metadata": {
        "id": "7WK0wN6igsnT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "graphs = graphs_gen.generate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykoac2bwYPYf",
        "outputId": "ba33e228-9412-4304-c994-b101efa3c399"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Collecting Nodes ... \n",
            "--- Collecting Edges ...\n",
            "--- Collecting Node Attributes ...\n",
            "--- Collecting Graph Labels ...\n",
            "CPU times: user 14.4 s, sys: 1.16 s, total: 15.5 s\n",
            "Wall time: 15.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_graph(G : Union[nx.Graph, nx.DiGraph], name: str) -> None:\n",
        "    \"\"\"\n",
        "    Plot a graph\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    graph : Union[nx.Graph, nx.DiGraph]\n",
        "        Just a nx.Graph object\n",
        "    name  : str\n",
        "        The name of the graph\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "    \"\"\"\n",
        "    # Getting the 3D Spring layout\n",
        "    layout = nx.spring_layout(G, dim=3, seed=18)\n",
        "    \n",
        "    # Getting nodes coordinate\n",
        "    x_nodes = [layout[i][0] for i in layout]  # x-coordinates of nodes\n",
        "    y_nodes = [layout[i][1] for i in layout]  # y-coordinates of nodes\n",
        "    z_nodes = [layout[i][2] for i in layout]  # z-coordinates of nodes\n",
        "    \n",
        "    # Getting a list of edges and create a list with coordinates\n",
        "    elist = G.edges()\n",
        "    x_edges, y_edges, z_edges = [], [], []\n",
        "    for edge in elist:\n",
        "        x_edges += [layout[edge[0]][0], layout[edge[1]][0], None]\n",
        "        y_edges += [layout[edge[0]][1], layout[edge[1]][1], None]\n",
        "        z_edges += [layout[edge[0]][2], layout[edge[1]][2], None]\n",
        "\n",
        "    colors = np.linspace(0, len(x_nodes))\n",
        "        \n",
        "    # Create a trace for the edges\n",
        "    etrace = go.Scatter3d(x=x_edges,\n",
        "                          y=y_edges,\n",
        "                          z=z_edges,\n",
        "                          mode='lines',\n",
        "                          line=dict(color='rgb(125,125,125)', width=1),\n",
        "                          hoverinfo='none'\n",
        "                         )\n",
        "    \n",
        "    # Create a trace for the nodes\n",
        "    ntrace = go.Scatter3d(x=x_nodes,\n",
        "                          y=y_nodes,\n",
        "                          z=z_nodes,\n",
        "                          mode='markers',\n",
        "                          marker=dict(\n",
        "                              symbol='circle',\n",
        "                              size=6,\n",
        "                              color=colors,\n",
        "                              colorscale='Viridis',\n",
        "                              line=dict(color='rgb(50,50,50)', width=.5)),\n",
        "                          text=list(layout.keys()),\n",
        "                          hoverinfo='text'\n",
        "                         )\n",
        "    \n",
        "    # Set the axis\n",
        "    axis = dict(showbackground=False,\n",
        "                showline=False,\n",
        "                zeroline=False,\n",
        "                showgrid=False,\n",
        "                showticklabels=False,\n",
        "                title='')\n",
        "    \n",
        "    # Create a layout for the plot\n",
        "    go_layout = go.Layout(title=f\"{name} Network Graph\",\n",
        "                          width=600,\n",
        "                          height=600,\n",
        "                          showlegend=False,\n",
        "                          scene=dict(xaxis=dict(axis),\n",
        "                                     yaxis=dict(axis),\n",
        "                                     zaxis=dict(axis)),\n",
        "                          margin=dict(t=100),\n",
        "                          hovermode='closest'\n",
        "                         )\n",
        "    \n",
        "    # Plot\n",
        "    data = [etrace, ntrace]\n",
        "    fig = go.Figure(data=data, layout=go_layout)\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "0-oeNL0tCohJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_graph(graphs[\"1\"][0], \"1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "B4qSXar2C5kG",
        "outputId": "ed94d253-30e5-4ced-da72-dc67a584f892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"a863d89e-07dc-4607-8b5b-190e1990ffb9\" class=\"plotly-graph-div\" style=\"height:600px; width:600px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a863d89e-07dc-4607-8b5b-190e1990ffb9\")) {                    Plotly.newPlot(                        \"a863d89e-07dc-4607-8b5b-190e1990ffb9\",                        [{\"hoverinfo\":\"none\",\"line\":{\"color\":\"rgb(125,125,125)\",\"width\":1},\"mode\":\"lines\",\"x\":[0.051308883149026346,0.02016575910818628,null,0.051308883149026346,0.08564240022999603,null,0.051308883149026346,0.1930411338709562,null,0.051308883149026346,-0.06827302872628031,null,-0.12547267262457984,0.02016575910818628,null,-0.12547267262457984,-0.281459921274044,null,0.02016575910818628,0.12118761521740949,null,0.08564240022999603,0.12044570801943036,null,0.08140990800553129,0.12044570801943036,null,0.08140990800553129,0.12118761521740949,null,0.08140990800553129,0.19699241882997393,null,0.08140990800553129,-0.06827302872628031,null,0.11514806279823737,0.2093998420450953,null,0.11514806279823737,0.12044570801943036,null,0.11514806279823737,0.19699241882997393,null,0.11514806279823737,-0.06827302872628031,null,-0.281459921274044,-0.27809972630529395,null,-0.281459921274044,-0.3728717992154575,null,-0.46995601540930576,-0.27809972630529395,null,-0.46995601540930576,-0.6136479395192319,null,0.16017564282786834,0.12044570801943036,null,0.2093998420450953,0.31628309097936935,null,0.2093998420450953,0.12118761521740949,null,0.31628309097936935,0.39709010030679426,null,-0.27809972630529395,-0.2167143756043442,null,-0.27809972630529395,-0.06827302872628031,null,-0.2167143756043442,-0.06827302872628031,null,0.19699241882997393,0.1930411338709562,null],\"y\":[0.16329421839396177,0.1035590663862065,null,0.16329421839396177,0.1914651750057414,null,0.16329421839396177,0.2031864708507348,null,0.16329421839396177,0.04465654231583099,null,0.1372103978148319,0.1035590663862065,null,0.1372103978148319,0.12640864381245945,null,0.1035590663862065,-0.02601491047409722,null,0.1914651750057414,0.06565167243282984,null,0.03774466927409536,0.06565167243282984,null,0.03774466927409536,-0.02601491047409722,null,0.03774466927409536,0.07838553438668093,null,0.03774466927409536,0.04465654231583099,null,-0.030577974580348444,-0.161478694007113,null,-0.030577974580348444,0.06565167243282984,null,-0.030577974580348444,0.07838553438668093,null,-0.030577974580348444,0.04465654231583099,null,0.12640864381245945,0.050616159724978696,null,0.12640864381245945,0.17457277552094932,null,0.005560467288952234,0.050616159724978696,null,0.005560467288952234,-0.027198657073935865,null,0.08730199329133351,0.06565167243282984,null,-0.161478694007113,-0.31753427209497487,null,-0.161478694007113,-0.02601491047409722,null,-0.31753427209497487,-0.4336633617864453,null,0.050616159724978696,0.0317022806306362,null,0.050616159724978696,0.04465654231583099,null,0.0317022806306362,0.04465654231583099,null,0.07838553438668093,0.2031864708507348,null],\"z\":[0.03190465965968714,-0.12000965528816555,null,0.03190465965968714,0.18661895709418716,null,0.03190465965968714,0.05332319506728771,null,0.03190465965968714,0.039012542028541014,null,-0.22460945060482918,-0.12000965528816555,null,-0.22460945060482918,-0.2252199230622716,null,-0.12000965528816555,-0.048569992831610176,null,0.18661895709418716,0.2337722510058344,null,0.09037282125889595,0.2337722510058344,null,0.09037282125889595,-0.048569992831610176,null,0.09037282125889595,0.09449564731215306,null,0.09037282125889595,0.039012542028541014,null,0.10000515223246463,-0.0030748232694585995,null,0.10000515223246463,0.2337722510058344,null,0.10000515223246463,0.09449564731215306,null,0.10000515223246463,0.039012542028541014,null,-0.2252199230622716,-0.059104515467852045,null,-0.2252199230622716,-0.3381390410238263,null,-0.05727043401103914,-0.059104515467852045,null,-0.05727043401103914,-0.05711260863666316,null,0.3904940304452934,0.2337722510058344,null,-0.0030748232694585995,-0.0494942482803942,null,-0.0030748232694585995,-0.048569992831610176,null,-0.0494942482803942,-0.08406286666203862,null,-0.059104515467852045,0.03344358099512942,null,-0.059104515467852045,0.039012542028541014,null,0.03344358099512942,0.039012542028541014,null,0.09449564731215306,0.05332319506728771,null],\"type\":\"scatter3d\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":[0.0,0.46938775510204084,0.9387755102040817,1.4081632653061225,1.8775510204081634,2.3469387755102042,2.816326530612245,3.285714285714286,3.7551020408163267,4.224489795918368,4.6938775510204085,5.163265306122449,5.63265306122449,6.1020408163265305,6.571428571428572,7.040816326530613,7.510204081632653,7.979591836734694,8.448979591836736,8.918367346938776,9.387755102040817,9.857142857142858,10.326530612244898,10.795918367346939,11.26530612244898,11.73469387755102,12.204081632653061,12.673469387755103,13.142857142857144,13.612244897959185,14.081632653061225,14.551020408163266,15.020408163265307,15.489795918367347,15.959183673469388,16.42857142857143,16.89795918367347,17.367346938775512,17.836734693877553,18.306122448979593,18.775510204081634,19.244897959183675,19.714285714285715,20.183673469387756,20.653061224489797,21.122448979591837,21.591836734693878,22.06122448979592,22.53061224489796,23.0],\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"line\":{\"color\":\"rgb(50,50,50)\",\"width\":0.5},\"size\":6,\"symbol\":\"circle\"},\"mode\":\"markers\",\"text\":[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\"],\"x\":[0.051308883149026346,-0.12547267262457984,0.02016575910818628,0.08564240022999603,0.08140990800553129,0.11514806279823737,-0.281459921274044,-0.46995601540930576,0.16017564282786834,0.2093998420450953,0.31628309097936935,0.7302829627834423,0.12044570801943036,-0.27809972630529395,0.12118761521740949,-0.2167143756043442,-0.6136479395192319,0.19699241882997393,0.1930411338709562,-0.3728717992154575,-0.06827302872628031,0.39709010030679426,-0.37207804949277984],\"y\":[0.16329421839396177,0.1372103978148319,0.1035590663862065,0.1914651750057414,0.03774466927409536,-0.030577974580348444,0.12640864381245945,0.005560467288952234,0.08730199329133351,-0.161478694007113,-0.31753427209497487,0.156225493319548,0.06565167243282984,0.050616159724978696,-0.02601491047409722,0.0317022806306362,-0.027198657073935865,0.07838553438668093,0.2031864708507348,0.17457277552094932,0.04465654231583099,-0.4336633617864453,-0.6610736904328566],\"z\":[0.03190465965968714,-0.22460945060482918,-0.12000965528816555,0.18661895709418716,0.09037282125889595,0.10000515223246463,-0.2252199230622716,-0.05727043401103914,0.3904940304452934,-0.0030748232694585995,-0.0494942482803942,-0.9867752779613245,0.2337722510058344,-0.059104515467852045,-0.048569992831610176,0.03344358099512942,-0.05711260863666316,0.09449564731215306,0.05332319506728771,-0.3381390410238263,0.039012542028541014,-0.08406286666203862,1.0],\"type\":\"scatter3d\"}],                        {\"height\":600,\"hovermode\":\"closest\",\"margin\":{\"t\":100},\"scene\":{\"xaxis\":{\"showbackground\":false,\"showgrid\":false,\"showline\":false,\"showticklabels\":false,\"title\":{\"text\":\"\"},\"zeroline\":false},\"yaxis\":{\"showbackground\":false,\"showgrid\":false,\"showline\":false,\"showticklabels\":false,\"title\":{\"text\":\"\"},\"zeroline\":false},\"zaxis\":{\"showbackground\":false,\"showgrid\":false,\"showline\":false,\"showticklabels\":false,\"title\":{\"text\":\"\"},\"zeroline\":false}},\"showlegend\":false,\"title\":{\"text\":\"1 Network Graph\"},\"width\":600,\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a863d89e-07dc-4607-8b5b-190e1990ffb9');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset, Few-Shot Sampler and DataLoader"
      ],
      "metadata": {
        "id": "8Y1vBGpK47ao"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Some useful definitions\n",
        "\n",
        "- **Episodic Training**: at training stage the algorithm sample a *Task*\n",
        "- **Task**: a pair (support set, query set)\n",
        "- **Support Set**: $D_{sup}^{train} = \\{(G_i^{train}, \\mathbf{y}_{i}^{train})\\}_{i=1}^s$, where $s = N \\times K$\n",
        "- **Query Set**: $D_{que}^{train} = \\{(G_i^{train}, \\mathbf{y}_{i}^{train})\\}_{i=1}^q$, where $q$ is the number of query data\n",
        "\n",
        "*Problem Definition*\n",
        "\n",
        "Given graph data $\\mathcal{G} = \\{(G_1, \\mathbf{y}_1), ..., (G_n, \\mathbf{y}_n)\\}$, we split it into train, $\\{(G^{train}, \\mathbf{y}^{train})\\}$, and test dataset, $\\{(G^{test}, \\mathbf{y}^{test})\\}$. Notice that $\\mathbf{y}^{train}$ and $\\mathbf{y}^{test}$ must have no common classes. For training, we use episodic training method. Given labeled support data, the goal is to predict the labels of query data. Note that in a single task, support data and query data share the same class space. At test stage when performing classification tasks on unseen classes, we firstly fine tune the meta-learner on the support data of test classes, then report classification performance on the test query set."
      ],
      "metadata": {
        "id": "70m7ZCsXkLhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphDataset(gdata.Dataset):\n",
        "    def __init__(self, graphs_ds: Dict[str, Tuple[nx.Graph, str]]) -> None:\n",
        "        super(GraphDataset, self).__init__()\n",
        "        self.graphs_ds = graphs_ds\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return f\"GraphDataset(classes={set(self.targets().tolist())},n_graphs={self.len()})\"\n",
        "\n",
        "    def indices(self) -> List[str]:\n",
        "        \"\"\" Return all the graph IDs \"\"\"\n",
        "        return list(self.graphs_ds.keys())\n",
        "\n",
        "    def len(self) -> int:\n",
        "        return len(self.graphs_ds.keys())\n",
        "\n",
        "    def targets(self) -> torch.Tensor:\n",
        "        \"\"\" Return all the labels \"\"\"\n",
        "        targets = []\n",
        "        for _, graph in self.graphs_ds.items():\n",
        "            targets.append(int(graph[1]))\n",
        "\n",
        "        return torch.tensor(targets)\n",
        "    \n",
        "    def get(self, idx: Union[int, str]) -> gdata.Data:\n",
        "        \"\"\" Return (Graph object, Adjacency matrix and label) of a graph \"\"\"\n",
        "        if isinstance(idx, str):\n",
        "            idx = int(idx)\n",
        "\n",
        "        graph    = self.graphs_ds[str(idx)]\n",
        "        g, label = graph[0].to_directed(), graph[1]\n",
        "        \n",
        "        # Retrieve nodes attributes\n",
        "        attrs = list(g.nodes(data=True))\n",
        "        x     = torch.tensor([list(map(int, a.values())) for _, a in attrs], dtype=torch.float)\n",
        "\n",
        "        # Retrieve edges\n",
        "        edge_index = torch.tensor([list(e) for e in g.edges], dtype=torch.long) \\\n",
        "                          .t()                                                  \\\n",
        "                          .contiguous()\n",
        "\n",
        "        # Retrieve ground trouth labels\n",
        "        y = torch.tensor([int(label)], dtype=torch.int)\n",
        "\n",
        "        return gdata.Data(x=x, edge_index=edge_index, y=y)\n",
        "\n",
        "    @classmethod\n",
        "    def dataset_from_labels(cls, mask   : torch.Tensor,\n",
        "                                 classes: torch.Tensor,\n",
        "                                 graphs : Dict[str, Tuple[nx.Graph, str]]\n",
        "    ) -> 'GraphDataset':\n",
        "        \"\"\" Return a new Dataset containing only graphs with specific labels \"\"\"\n",
        "        filter = classes[(mask[:, None] == classes[None, :]).any(dim=0)].numpy()\\\n",
        "                 .astype(str)\\\n",
        "                 .tolist()\n",
        "\n",
        "        filtered_graphs = {k : v for k, v in graphs.items() if v[1] in filter}\n",
        "        graph_dataset   = super(GraphDataset, cls).__new__(cls)\n",
        "\n",
        "        graph_dataset.__init__(filtered_graphs)\n",
        "\n",
        "        return graph_dataset\n",
        "\n",
        "\n",
        "\n",
        "def get_all_labels(graphs: Dict[str, Tuple[nx.Graph, str]]) -> torch.Tensor:\n",
        "    \"\"\" Return a list containings all labels of the dataset \"\"\"\n",
        "    return torch.tensor(list(set([int(v[1]) for _, v in graphs.items()])))\n",
        "\n",
        "\n",
        "def generate_train_val_test(graphs    : Dict[str, Tuple[nx.Graph, str]],\n",
        "                            perc_test : float,\n",
        "                            perc_train: float,\n",
        "                            perc_val  : float\n",
        ") -> Tuple[GraphDataset, GraphDataset, GraphDataset]:\n",
        "    \"\"\" Return dataset for training, validation and testing \"\"\"\n",
        "    classes = get_all_labels(graphs)\n",
        "    n_class = len(classes)\n",
        "    perm    = torch.randperm(n_class) + 1\n",
        "\n",
        "    q_train = n_class * perc_train // 100\n",
        "    q_test  = n_class * perc_test  // 100\n",
        "    q_val   = n_class * perc_val   // 100\n",
        "\n",
        "    \n",
        "    train_perm = perm[:q_train]\n",
        "    test_perm  = perm[q_train: q_train + q_test]\n",
        "    val_perm   = perm[q_train + q_test:]\n",
        "    \n",
        "    train_ds = GraphDataset.dataset_from_labels(train_perm, classes, graphs)\n",
        "    test_ds  = GraphDataset.dataset_from_labels(test_perm,  classes, graphs)\n",
        "    val_ds   = GraphDataset.dataset_from_labels(val_perm,   classes, graphs)\n",
        "\n",
        "    return train_ds, test_ds, val_ds"
      ],
      "metadata": {
        "id": "p01mD1pSHtTX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds, test_ds, val_ds = generate_train_val_test(graphs, perc_train=50, perc_test=30, perc_val=20)\n",
        "train_ds, test_ds, val_ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjByzJOhubeo",
        "outputId": "e0a8de15-0c55-4d0c-c9e8-efc8d37f4f50"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(GraphDataset(classes={1, 4, 7, 8, 10},n_graphs=22500),\n",
              " GraphDataset(classes={2, 5, 6},n_graphs=13500),\n",
              " GraphDataset(classes={9, 3},n_graphs=9000))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sampler Pseudo-Code**\n",
        "\n",
        "```\n",
        "function iter_sample_NKshot_with_Query(\n",
        "\tData:\n",
        "\t\t- G(train)  --> train set\n",
        "\t\t- d --> dimension of the train set\n",
        "\t\t- c --> number of classes of the train set\n",
        "\t\t- N --> Number of classes to select\n",
        "\t\t- K --> Number of support sample per class\n",
        "\t\t- Q --> Number of query sample per class\n",
        "\t\t- epoch_size --> number of batches per epoch\n",
        "){\n",
        "\ttarget_classes = random.sample(from=unique(y(train, i), i=1...d), size=N)\n",
        "\n",
        "\tfor (i=1...epoch_size) do\n",
        "\t{\n",
        "\t\tforeach (cl <- target_classes) do \n",
        "\t\t{\n",
        "\t\t\tfiltered_data = filter(data=G(train),by=Lambda(x, x.y == cl))\n",
        "\t\t\tf = |filtered_data|\n",
        "\n",
        "\t\t\tIMPORTANT: assert(f >= K + Q)\n",
        "\n",
        "\t\t\tselected_data = random.sample(from=filtered_data, size=(K + Q))\t\n",
        "\t\t\tsupport_data = selected_data.slice(start=0, end=K)\n",
        "\t\t\tquery_data = selected_data.slice(start=K, end=(K + Q))\n",
        "\n",
        "\t\t\tgenerate(support_data, query_data)\n",
        "\t\t}\n",
        "\t}\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "tWJyjfFw6d4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NWayKShotSampler(torch.utils.data.Sampler):\n",
        "    \"\"\"\n",
        "    In few-shot classification, and in particular in Meta-Learning, \n",
        "    we use a specific way of sampling batches from the training/val/test \n",
        "    set. This way is called N-way-K-shot, where N is the number of classes \n",
        "    to sample per batch and K is the number of examples to sample per class \n",
        "    in the batch. The sample batch on which we train our model is also called \n",
        "    `support` set, while the one on which we test is called `query` set.\n",
        "\n",
        "    This class is a N-way-K-shot sampler that will be used as a batch_sampler\n",
        "    for the :obj:`torch_geometric.loader.DataLoader` dataloader. This sampler\n",
        "    return batches of indices that correspond to support and query set batches.\n",
        "\n",
        "    Attributes:\n",
        "        labels: PyTorch tensor of the labels of the data elements\n",
        "        n_way: Number of classes to sampler per batch\n",
        "        k_shot: Number of examples to sampler per class in the batch\n",
        "        n_query: Number of query example to sample per class in the batch\n",
        "        shuffle: If True, examples and classes are shuffled at each iteration\n",
        "        indices_per_class: How many indices per classes\n",
        "        classes: list of all classes\n",
        "        epoch_size: number of batches per epoch\n",
        "    \"\"\"\n",
        "    def __init__(self, labels       : torch.Tensor, \n",
        "                       n_way        : int, \n",
        "                       k_shot       : int,\n",
        "                       n_query      : int,\n",
        "                       epoch_size   : int,\n",
        "                       shuffle      : bool=True) -> None:\n",
        "        super().__init__(None)\n",
        "        self.labels = labels\n",
        "        self.n_way = n_way\n",
        "        self.k_shot = k_shot\n",
        "        self.n_query = n_query\n",
        "        self.shuffle = shuffle\n",
        "        self.epoch_size = epoch_size\n",
        "\n",
        "        self.classes = torch.unique(self.labels).tolist()\n",
        "        self.indices_per_class = dict()\n",
        "        for cl in self.classes:\n",
        "            self.indices_per_class[cl] = torch.where(self.labels == cl)[0]\n",
        "    \n",
        "    def shuffle_data(self) -> None:\n",
        "        \"\"\"\n",
        "        Shuffle the examples per class\n",
        "        \n",
        "        Args:\n",
        "            classes: The list of all classes\n",
        "        \"\"\"\n",
        "        for cl in self.classes:\n",
        "            perm = torch.randperm(self.indices_per_class[cl].shape[0])\n",
        "            self.indices_per_class[cl] = self.indices_per_class[cl][perm]\n",
        "\n",
        "    def __iter__(self) -> List[torch.Tensor]:\n",
        "        # Shuffle the data\n",
        "        if self.shuffle:\n",
        "            self.shuffle_data()\n",
        "\n",
        "        target_classes = random.sample(self.classes, self.n_way)\n",
        "        for _ in range(self.epoch_size):\n",
        "            n_way_k_shot_n_query = []\n",
        "            for cl in target_classes:\n",
        "                labels_per_class = self.indices_per_class[cl]\n",
        "                assert len(labels_per_class) >= self.k_shot + self.n_query\n",
        "                selected_data = random.sample(labels_per_class.tolist(), self.k_shot + self.n_query)\n",
        "                n_way_k_shot_n_query.append(selected_data)\n",
        "\n",
        "            yield torch.tensor(n_way_k_shot_n_query)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self.epoch_size"
      ],
      "metadata": {
        "id": "k3xa2BT_yhyi"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TaskBatchSampler(torch.utils.data.Sampler):\n",
        "    \"\"\"Sample a batch of tasks\"\"\"\n",
        "\n",
        "    def __init__(self, dataset_targets: torch.Tensor,\n",
        "                       batch_size     : int,\n",
        "                       n_way          : int,\n",
        "                       k_shot         : int,\n",
        "                       n_query        : int,\n",
        "                       epoch_size     : int,\n",
        "                       shuffle        : bool = True) -> None:\n",
        "    \n",
        "        super().__init__(None)\n",
        "        self.task_sampler = NWayKShotSampler(\n",
        "            dataset_targets,\n",
        "            n_way=n_way,\n",
        "            k_shot=k_shot,\n",
        "            n_query=n_query,\n",
        "            epoch_size=epoch_size,\n",
        "            shuffle=shuffle\n",
        "        )\n",
        "\n",
        "        self.task_batch_size = batch_size\n",
        "    \n",
        "    def __iter__(self):\n",
        "        mini_batches = []\n",
        "        for task_idx, task in enumerate(self.task_sampler):\n",
        "            mini_batches.extend(task.tolist())\n",
        "            if (task_idx + 1) % self.task_batch_size == 0:\n",
        "                yield torch.tensor(mini_batches).flatten().tolist()\n",
        "                mini_batches = []\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.task_sampler) // self.task_batch_size\n",
        "    \n",
        "    def create_batches_from_data_batch(self, data_batch: gdata.batch.DataBatch):\n",
        "        \"\"\"\n",
        "        Assume L = [x1, x2, x3, ..., xN] is the data_batch\n",
        "        each xi is a graph. Moreover, we have that\n",
        "        L[0:K] = support sample for the first class\n",
        "        L[K+1:K+Q] = query sample for the first class\n",
        "        In general, we have that \n",
        "        \n",
        "              L[i * (K + Q) : (i + 1) * (K + Q)]\n",
        "    \n",
        "        is the (support, query) pair for the i-th class\n",
        "        Finally, the first batch is the one that goes from\n",
        "        L[0 : N * (K + Q)], so\n",
        "        \n",
        "              L[i * N * (K + Q) : (i + 1) * N * (K + Q)]\n",
        "    \n",
        "        is the i-th batch. \n",
        "        \"\"\"\n",
        "        n_way = self.task_sampler.n_way\n",
        "        k_shot = self.task_sampler.k_shot\n",
        "        n_query = self.task_sampler.n_query\n",
        "\n",
        "        total_support_query_number = n_way * (k_shot + n_query)\n",
        "        support_plus_query = k_shot + n_query\n",
        "\n",
        "        # Initialize batch list for support and query set\n",
        "        support_data_batch = []\n",
        "        query_data_batch = []\n",
        "\n",
        "        # I know how many batch do I have, so\n",
        "        for batch_number in range(self.task_batch_size):\n",
        "\n",
        "            # I also know how many class do I have in a task\n",
        "            for class_number in range(n_way):\n",
        "\n",
        "                # First of all let's take the i-th batch\n",
        "                data_batch_slice = slice(\n",
        "                    batch_number * total_support_query_number, \n",
        "                    (batch_number + 1) * total_support_query_number\n",
        "                )\n",
        "                data_batch_per_batch = data_batch[data_batch_slice]\n",
        "\n",
        "                # Then let's take the (support, query) pair for a class\n",
        "                support_query_slice = slice(\n",
        "                    class_number * support_plus_query,\n",
        "                    (class_number + 1) * support_plus_query\n",
        "                )\n",
        "                support_query_data = data_batch_per_batch[support_query_slice]\n",
        "\n",
        "                # Divide support from query\n",
        "                support_data = support_query_data[:k_shot]\n",
        "                query_data = support_query_data[k_shot:support_plus_query]\n",
        "\n",
        "                support_data_batch += support_data\n",
        "                query_data_batch += query_data\n",
        "        \n",
        "        # Create new DataBatchs and return\n",
        "        return gdata.Batch.from_data_list(support_data_batch), gdata.Batch.from_data_list(query_data_batch)"
      ],
      "metadata": {
        "id": "-92CSCcTag6A"
      },
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphCollater(gloader.dataloader.Collater):\n",
        "    def __init__(self, *args) -> None:\n",
        "        super(GraphCollater, self).__init__(*args)\n",
        "    \n",
        "    def __call__(self, batch: Generic[T]) -> Generic[T]:\n",
        "        elem = batch[0]\n",
        "        if isinstance(elem, GraphDataset):\n",
        "            return self(elem)\n",
        "        \n",
        "        return super(GraphCollater, self).__call__(batch)\n",
        "\n",
        "class FewShotDataLoader(torch.utils.data.DataLoader):\n",
        "    \"\"\"Custom DataLoader for GraphDataset\"\"\"\n",
        "    def __init__(self, dataset   : GraphDataset,\n",
        "                       batch_size: int = 1,\n",
        "                       shuffle   : bool=False,\n",
        "                       follow_batch: Optional[List[str]]=None,\n",
        "                       exclude_keys: Optional[List[str]]=None,\n",
        "                       **kwargs) -> None:\n",
        "\n",
        "        if 'collate_fn' in kwargs:\n",
        "            del kwargs[\"collate_fn\"]\n",
        "\n",
        "        self.follow_batch = follow_batch\n",
        "        self.exclude_keys = exclude_keys\n",
        "\n",
        "        # Take the batch sampler\n",
        "        self.batch_sampler = kwargs[\"batch_sampler\"]\n",
        "\n",
        "        super().__init__(\n",
        "            dataset,\n",
        "            batch_size,\n",
        "            shuffle,\n",
        "            collate_fn=GraphCollater(follow_batch, exclude_keys),\n",
        "            **kwargs,\n",
        "        )\n",
        "    \n",
        "    def __iter__(self):\n",
        "        for x in super().__iter__():\n",
        "            support_batch, query_batch = self.batch_sampler.create_batches_from_data_batch(x)\n",
        "            yield support_batch, query_batch"
      ],
      "metadata": {
        "id": "sUv4OxoykplC"
      },
      "execution_count": 264,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_WAY   = 5\n",
        "K_SHOT  = 5\n",
        "N_QUERY = 5"
      ],
      "metadata": {
        "id": "SkZxH2VO3PH7"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_train_loader = FewShotDataLoader(\n",
        "    dataset=train_ds,\n",
        "    batch_sampler=TaskBatchSampler(\n",
        "        dataset_targets=train_ds.targets(),\n",
        "        n_way=N_WAY,\n",
        "        k_shot=K_SHOT,\n",
        "        n_query=N_QUERY,\n",
        "        epoch_size=10,\n",
        "        shuffle=True,\n",
        "        batch_size=2\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "4Q6lQr_5IxuC"
      },
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "support, query = next(iter(graph_train_loader))"
      ],
      "metadata": {
        "id": "tKbvAyXdfudB"
      },
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "support"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r689_7zrf9A3",
        "outputId": "93b66a4b-7433-4c2e-9002-3634e54940e8"
      },
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataBatch(x=[1124, 1], edge_index=[2, 3556], y=[50], batch=[1124], ptr=[51])"
            ]
          },
          "metadata": {},
          "execution_count": 273
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZR_VkfAf-bs",
        "outputId": "991c4c3a-025f-4584-c3bb-5d1fb3a3412e"
      },
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataBatch(x=[1256, 1], edge_index=[2, 4146], y=[50], batch=[1256], ptr=[51])"
            ]
          },
          "metadata": {},
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adaptive-Step MAML"
      ],
      "metadata": {
        "id": "mBk74Q0vBFMH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some important configurations"
      ],
      "metadata": {
        "id": "XAUPKK1GMPBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "POOLING_RATIO = 0.5\n",
        "DROPOUT_RATIO = 0.3\n",
        "\n",
        "OUTER_LR     = 0.001\n",
        "INNER_LR     = 0.01\n",
        "STOP_LR      = 0.0001\n",
        "WEIGHT_DECAY = 1E-05\n",
        "\n",
        "MAX_STEP      = 15\n",
        "MIN_STEP      = 5\n",
        "STEP_TEST     = 15\n",
        "FLEXIBLE_STEP = True\n",
        "STEP_PENALITY = 0.001\n",
        "USE_SCORE     = True\n",
        "USE_GRAD      = False\n",
        "USE_LOSS      = True\n",
        "\n",
        "# Episodes: How many tasks to run\n",
        "\n",
        "TRAIN_SHOT         = 10   # K-shot for training set\n",
        "VAL_SHOT           = 10   # K-shot for validation (or test) set\n",
        "TRAIN_QUERY        = 15   # Number of query for the training set\n",
        "VAL_QUERY          = 15   # Number of query for the validation (or test) set\n",
        "TRAIN_WAY          = 3    # N-way for training set\n",
        "TEST_WAY           = 3    # N-way for test set\n",
        "VAL_EPISODE        = 200  # Number of episodes for validation\n",
        "TRAIN_EPISODE      = 200  # Number of episodes for training\n",
        "BATCH_PER_EPISODES = 5    # How many batch per episode\n",
        "EPOCHS             = 500  # How many epochs\n",
        "PATIENCE           = 35\n",
        "GRAD_CLIP          = 5"
      ],
      "metadata": {
        "id": "JbquOJh7MSSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhyPOaEh1oQC"
      },
      "outputs": [],
      "source": [
        "class GCN4MAML(nn.Module):\n",
        "    \"\"\" Class for a Graph Convolutional Network used in AS-MAML. \"\"\"\n",
        "    def __init__(self) -> None:\n",
        "        super(GCN4MAML, self).__init__()\n",
        "\n",
        "class StopControl(nn.Module):\n",
        "    def __init__(self, input_size: int, hidden_size: int) -> None:\n",
        "        super(StopControl, self).__init__()\n",
        "        self.lstm = nn.LSTMCell(input_size=input_size, hidden_size=hidden_size)\n",
        "        self.output_layer = nn.Linear(hidden_size, 1)\n",
        "        self.output_layer.bias.data.fill_(0.0)\n",
        "        self.h_0 = nn.Parameter(torch.randn((hidden_size, ), requires_grad=True))\n",
        "        self.c_0 = nn.Parameter(torch.randn((hidden_size, ), requires_grad=True))\n",
        "\n",
        "    def forward(self, inputs, hx) -> torch.Tensor:\n",
        "        if hx is None:\n",
        "            hx = (self.h_0.unsqueeze(0), self.c_0.unsqueeze(0))\n",
        "        \n",
        "        h, c = self.lstm(inputs, hx)\n",
        "        return torch.sigmoid(self.output_layer(h).unsqueeze(0)), (h, c)\n",
        "\n",
        "class AdaptiveStepMAML(nn.Module):\n",
        "    \"\"\" The Meta-Learner Class \"\"\"\n",
        "    def __init__(self, model, \n",
        "                       inner_lr    : float=INNER_LR, \n",
        "                       outer_lr    : float=OUTER_LR, \n",
        "                       stop_lr     : float=STOP_LR, \n",
        "                       weight_decay: float=WEIGHT_DECAY) -> None:\n",
        "\n",
        "        self.net          = model\n",
        "        self.inner_lr     = inner_lr\n",
        "        self.outer_lr     = outer_lr\n",
        "        self.stop_lr      = stop_lr\n",
        "        self.weight_decay = weight_decay\n",
        "\n",
        "        self.stop_prob = 0.5\n",
        "        self.stop_gate = self.StopControl(2, 20)\n",
        "\n",
        "        self.meta_optim = self.configure_optimizers()\n",
        "\n",
        "        self.loss      = nn.BCEWithLogitsLoss()\n",
        "        self.scheduler = optim.lr_scheduler.ExponentialLR(self.meta_optim,\n",
        "                                                          gamma=.5,\n",
        "                                                          last_epoch=-1,\n",
        "                                                          verbose=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return optim.Adam([\n",
        "                           {'params': self.net.parameters(),       'lr': self.outer_lr},\n",
        "                           {'params': self.stop_gate.parameters(), 'lr': self.stop_lr}],\n",
        "                          lr=1e-04, weight_decay=self.weight_decay\n",
        "               )\n",
        "        \n",
        "    def compute_loss(self, logits, label) -> float:\n",
        "        return self.loss(logits.squeeze(), label.double().squeeze())\n",
        "\n",
        "    "
      ]
    }
  ]
}